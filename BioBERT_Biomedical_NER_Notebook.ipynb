{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8557e829",
   "metadata": {},
   "source": [
    "# Biomedical Named Entity Recognition with BioBERT\n",
    "\n",
    "**Ready-to-run Jupyter/Colab notebook** â€” train, evaluate, and run inference for biomedical NER using `dmis-lab/biobert-base-cased-v1.1` (HuggingFace).\n",
    "\n",
    "**Notebook contents**\n",
    "1. Install & setup\n",
    "2. Load dataset (BC5CDR example via `datasets`)\n",
    "3. Preprocessing & token-label alignment (BIO)\n",
    "4. Model setup (`PubMedBERT`)\n",
    "5. Training with `Trainer`\n",
    "6. Evaluation\n",
    "7. Inference helper & demo\n",
    "\n",
    "**Notes**\n",
    "- This notebook expects an environment with internet access (to download models/datasets). For Colab, select a GPU runtime.\n",
    "- If you're behind a firewall, download datasets and models manually and adjust paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e13e81122cbea9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T16:23:35.926585Z",
     "start_time": "2025-11-15T16:23:35.804354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.44 in ./env/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets>=2.21 in ./env/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: seqeval in ./env/lib/python3.13/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch in ./env/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.13/site-packages (from transformers>=4.44) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.13/site-packages (from transformers>=4.44) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.13/site-packages (from transformers>=4.44) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./env/lib/python3.13/site-packages (from datasets>=2.21) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./env/lib/python3.13/site-packages (from datasets>=2.21) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.13/site-packages (from datasets>=2.21) (2.3.3)\n",
      "Requirement already satisfied: xxhash in ./env/lib/python3.13/site-packages (from datasets>=2.21) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./env/lib/python3.13/site-packages (from datasets>=2.21) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./env/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (3.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in ./env/lib/python3.13/site-packages (from seqeval) (1.7.2)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./env/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./env/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./env/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.21) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/lib/python3.13/site-packages (from requests->transformers>=4.44) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.13/site-packages (from requests->transformers>=4.44) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.13/site-packages (from requests->transformers>=4.44) (2025.11.12)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./env/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.13/site-packages (from pandas->datasets>=2.21) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.13/site-packages (from pandas->datasets>=2.21) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.13/site-packages (from pandas->datasets>=2.21) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers>=4.44\" \"datasets>=2.21\" \"seqeval\" \"torch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7150e94",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb72066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import transformers, datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BertForTokenClassification\n",
    ")\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a38ac46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T14:23:32.588510Z",
     "start_time": "2025-11-15T14:23:32.575624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 4.57.1\n",
      "datasets 3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "print('transformers', transformers.__version__)\n",
    "print('datasets', datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb6403",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf671f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "DATASET_NAME = \"tner/bc5cdr\"  # pre-split, tokenized BC5CDR with tags:contentReference[oaicite:1]{index=1}\n",
    "\n",
    "label_list = [\"O\", \"B-Chemical\", \"B-Disease\", \"I-Disease\", \"I-Chemical\"]\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b950d",
   "metadata": {},
   "source": [
    "## Load dataset and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe30052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: tner/bc5cdr\n",
      "Splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5228\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5330\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5865\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (BC5CDR for chemicals/diseases) via HuggingFace datasets\n",
    "print(\"Loading dataset:\", DATASET_NAME)\n",
    "tner_dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "print(\"Splits:\", tner_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89710e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: dict_keys(['tokens', 'tags'])\n",
      "tokens sample: ['Naloxone', 'reverses', 'the', 'antihypertensive', 'effect', 'of', 'clonidine', '.']\n",
      "tags sample: [1, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Inspect an example\n",
    "example = tner_dataset['train'][0]\n",
    "print('keys:', example.keys())\n",
    "if 'tokens' in example:\n",
    "    print('tokens sample:', example['tokens'][:40])\n",
    "if 'tags' in example:\n",
    "    print('tags sample:', example['tags'][:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0dd6308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: tokenize and align labels (BIO scheme)\n",
    "print(\"Loading tokenizer:\", MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fb9ff",
   "metadata": {},
   "source": [
    "## Tokenization + label alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3952b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to align labels for tokenized inputs\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the list of token sequences and align the BIO labels\n",
    "    to the resulting wordpieces.\n",
    "\n",
    "    examples[\"tokens\"]: List[List[str]]\n",
    "    examples[\"tags\"]:   List[List[int]]  (indices into label_list)\n",
    "    \"\"\"\n",
    "        \n",
    "    tokenized = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,  # because we already have word tokens\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    \n",
    "    all_labels = examples['tags']\n",
    "    new_labels = []\n",
    "\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        # word_ids maps each subtoken position to its originating word index\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_id = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                # Special tokens (CLS, SEP, padding later)\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                original_label_id = labels[word_id]\n",
    "\n",
    "                if word_id != previous_word_id:\n",
    "                    # First subtoken of the word: use original label\n",
    "                    label_ids.append(original_label_id)\n",
    "                else:\n",
    "                    # Subsequent subtokens of the same word:\n",
    "                    # convert B-* to I-* to respect BIO scheme\n",
    "                    if original_label_id == label2id[\"B-Chemical\"]:\n",
    "                        label_ids.append(label2id[\"I-Chemical\"])\n",
    "                    elif original_label_id == label2id[\"B-Disease\"]:\n",
    "                        label_ids.append(label2id[\"I-Disease\"])\n",
    "                    else:\n",
    "                        # For I-* or O, keep same\n",
    "                        label_ids.append(original_label_id)\n",
    "\n",
    "                previous_word_id = word_id\n",
    "\n",
    "        new_labels.append(label_ids)\n",
    "\n",
    "    tokenized[\"labels\"] = new_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce7b724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and aligning labels...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5228\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5330\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5865\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizing and aligning labels...\")\n",
    "remove_columns = tner_dataset[\"train\"].column_names  # [\"tokens\", \"tags\"]\n",
    "tokenized_datasets = tner_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns,\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f28d8c",
   "metadata": {},
   "source": [
    "## Data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ac1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a6f852",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b97577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBertForTokenClassification(BertForTokenClassification):\n",
    "    def __init__(self, config, label_weights=None):\n",
    "        super().__init__(config)\n",
    "        if label_weights is not None:\n",
    "            self.register_buffer(\"label_weights\", torch.tensor(label_weights, dtype=torch.float))\n",
    "        else:\n",
    "            self.label_weights = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs,  # <-- Required to absorb Trainer extra args\n",
    "    ):\n",
    "        # Run BERT encoder\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(\n",
    "                weight=self.label_weights,\n",
    "                ignore_index=-100\n",
    "            )\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels),\n",
    "                labels.view(-1)\n",
    "            )\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d35f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WeightedBertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight', 'label_weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model:\", MODEL_NAME)\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "label_weights = [1.0, 1.0, 1.5, 1.5, 1.0]  # [O, B-chem, B-dis, I-dis, I-chem]\n",
    "\n",
    "model = WeightedBertForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    config=config,\n",
    "    label_weights=label_weights,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e1056",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4348fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    p is an EvalPrediction with:\n",
    "    - p.predictions: np.array (batch, seq_len, num_labels)\n",
    "    - p.label_ids:   np.array (batch, seq_len)\n",
    "    \"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels: List[List[str]] = []\n",
    "    true_predictions: List[List[str]] = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        # filter out positions where label == -100\n",
    "        valid_indices = label_seq != -100\n",
    "        pred_seq = pred_seq[valid_indices]\n",
    "        label_seq = label_seq[valid_indices]\n",
    "\n",
    "        true_labels.append([id2label[int(l)] for l in label_seq])\n",
    "        true_predictions.append([id2label[int(p_i)] for p_i in pred_seq])\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4a42e",
   "metadata": {},
   "source": [
    "## Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af98b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pubmedbert_bc5cdr_weighted\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    dataloader_pin_memory=False,  # for MPS\n",
    "    label_smoothing_factor=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e6077",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd0c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer,          # or tokenizer=tokenizer on older HF\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdf016",
   "metadata": {},
   "source": [
    "## Training + evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dc6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation and test\n",
    "    print(\"Validation metrics:\")\n",
    "    val_metrics = trainer.evaluate(tokenized_datasets[\"validation\"])\n",
    "    print(val_metrics)\n",
    "\n",
    "    print(\"Test metrics:\")\n",
    "    test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "    print(test_metrics)\n",
    "\n",
    "    # Optional: detailed report on test set\n",
    "    print(\"Detailed seqeval report on test set:\")\n",
    "    predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        valid_indices = label_seq != -100\n",
    "        pred_seq = pred_seq[valid_indices]\n",
    "        label_seq = label_seq[valid_indices]\n",
    "\n",
    "        true_labels.append([id2label[int(l)] for l in label_seq])\n",
    "        true_predictions.append([id2label[int(p_i)] for p_i in pred_seq])\n",
    "\n",
    "    print(classification_report(true_labels, true_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1b09553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2616' max='2616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2616/2616 09:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.097584</td>\n",
       "      <td>0.869830</td>\n",
       "      <td>0.877177</td>\n",
       "      <td>0.873488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.092474</td>\n",
       "      <td>0.872252</td>\n",
       "      <td>0.901991</td>\n",
       "      <td>0.886873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.104711</td>\n",
       "      <td>0.868938</td>\n",
       "      <td>0.917318</td>\n",
       "      <td>0.892473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>0.879540</td>\n",
       "      <td>0.916588</td>\n",
       "      <td>0.897682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10697530210018158, 'eval_precision': 0.8795397698849424, 'eval_recall': 0.9165884683557501, 'eval_f1': 0.8976820177677933, 'eval_runtime': 24.237, 'eval_samples_per_second': 219.911, 'eval_steps_per_second': 27.52, 'epoch': 4.0}\n",
      "Test metrics:\n",
      "{'eval_loss': 0.11681059002876282, 'eval_precision': 0.8581758580794446, 'eval_recall': 0.9074319502497706, 'eval_f1': 0.8821168425746989, 'eval_runtime': 42.8298, 'eval_samples_per_second': 136.937, 'eval_steps_per_second': 17.138, 'epoch': 4.0}\n",
      "Detailed seqeval report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Chemical       0.91      0.93      0.92      5385\n",
      "     Disease       0.80      0.87      0.84      4424\n",
      "\n",
      "   micro avg       0.86      0.91      0.88      9809\n",
      "   macro avg       0.85      0.90      0.88      9809\n",
      "weighted avg       0.86      0.91      0.88      9809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8c2a4",
   "metadata": {},
   "source": [
    "## Inference helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8931759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_inference(text: str, max_length: int = 256):\n",
    "    \"\"\"\n",
    "    Run NER on a new biomedical sentence/abstract.\n",
    "    Returns entities with type and char spans.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize as raw text (not pre-split)\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded)\n",
    "        logits = outputs.logits  # (1, seq_len, num_labels)\n",
    "        pred_ids = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "    # Map subtokens back to words using tokenizer\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"][0])\n",
    "    # We will reconstruct entity spans in a simple way: group consecutive non-\"O\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    # skip [CLS] (0) and stop at [SEP]\n",
    "    for i, (token, label_id) in enumerate(zip(tokens, pred_ids)):\n",
    "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            if current_entity is not None:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "            if token == tokenizer.sep_token:\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        label = id2label[int(label_id)]\n",
    "        if label == \"O\":\n",
    "            if current_entity is not None:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "            continue\n",
    "\n",
    "        # label is B-* or I-*\n",
    "        label_type = label.split(\"-\", 1)[1]\n",
    "\n",
    "        # Approximate char span via tokenizer offsets\n",
    "        offsets = encoded.token_to_chars(i)\n",
    "        if offsets is None:\n",
    "            # This can happen rarely; we just skip char span\n",
    "            start_char, end_char = None, None\n",
    "        else:\n",
    "            start_char, end_char = offsets.start, offsets.end\n",
    "\n",
    "        if current_entity is None:\n",
    "            current_entity = {\n",
    "                \"type\": label_type,\n",
    "                \"text\": text[start_char:end_char] if start_char is not None else token,\n",
    "                \"start\": start_char,\n",
    "                \"end\": end_char,\n",
    "            }\n",
    "        else:\n",
    "            # Same type? continue span\n",
    "            if current_entity[\"type\"] == label_type:\n",
    "                if start_char is not None and end_char is not None:\n",
    "                    # extend span\n",
    "                    current_entity[\"end\"] = end_char\n",
    "                    current_entity[\"text\"] = text[current_entity[\"start\"]:current_entity[\"end\"]]\n",
    "            else:\n",
    "                # different type, close previous and start new\n",
    "                entities.append(current_entity)\n",
    "                current_entity = {\n",
    "                    \"type\": label_type,\n",
    "                    \"text\": text[start_char:end_char] if start_char is not None else token,\n",
    "                    \"start\": start_char,\n",
    "                    \"end\": end_char,\n",
    "                }\n",
    "\n",
    "    if current_entity is not None:\n",
    "        entities.append(current_entity)\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4009243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example inference:\n",
      "Text: Paracetamol can cause liver toxicity in high doses.\n",
      "{'type': 'Chemical', 'text': 'Paracetamol', 'start': 0, 'end': 11}\n",
      "{'type': 'Disease', 'text': 'liver toxicity', 'start': 22, 'end': 36}\n"
     ]
    }
   ],
   "source": [
    "# Example inference after training:\n",
    "example = \"Paracetamol can cause liver toxicity in high doses.\"\n",
    "ents = ner_inference(example)\n",
    "print(\"\\nExample inference:\")\n",
    "print(\"Text:\", example)\n",
    "for e in ents:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
